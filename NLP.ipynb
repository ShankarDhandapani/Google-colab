{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "NWLIGXxT7jIT"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShankarDhandapani/Google-colab/blob/master/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "xfF5lfi4mUn1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Natural Language Processing (NLP)"
      ]
    },
    {
      "metadata": {
        "id": "KkOhViNovUxF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Basic Imports\n",
        "import nltk\n",
        "import re\n",
        "import heapq   \n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6ijfxPo60ndb",
        "colab_type": "code",
        "outputId": "fca08e1d-a549-4891-d534-cd02af436fc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "cell_type": "code",
      "source": [
        "nltk.download('popular', halt_on_error=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "3LyDvDI3v8WU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ]
    },
    {
      "metadata": {
        "id": "wJlps2JwoLU7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Data\n",
        "data = \"It originated from the idea that there are readers who prefer learning new skills from the comforts of their drawing rooms\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DkmAgPp6v2Ht",
        "colab_type": "code",
        "outputId": "41e7f45e-1bc0-4a22-dbee-2bbdbbb211aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Tokenizing sentences\n",
        "sentences = nltk.sent_tokenize(data)\n",
        "sentences"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['It originated from the idea that there are readers who prefer learning new skills from the comforts of their drawing rooms']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "aOm0lu5WvWu8",
        "colab_type": "code",
        "outputId": "68710b4e-4637-4580-ef60-7851c4c3c12b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Tokenizing words\n",
        "words = nltk.word_tokenize(data)\n",
        "words"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['It',\n",
              " 'originated',\n",
              " 'from',\n",
              " 'the',\n",
              " 'idea',\n",
              " 'that',\n",
              " 'there',\n",
              " 'are',\n",
              " 'readers',\n",
              " 'who',\n",
              " 'prefer',\n",
              " 'learning',\n",
              " 'new',\n",
              " 'skills',\n",
              " 'from',\n",
              " 'the',\n",
              " 'comforts',\n",
              " 'of',\n",
              " 'their',\n",
              " 'drawing',\n",
              " 'rooms']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "CNs2butvwYq1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Stemming the words"
      ]
    },
    {
      "metadata": {
        "id": "8HE3oopsvrP8",
        "colab_type": "code",
        "outputId": "34b0cc57-e157-488d-c872-e1c291eb6eb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Stemming\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "porter_stemmer = PorterStemmer()\n",
        "# First Word tokenization\n",
        "nltk_tokens = nltk.word_tokenize(data)\n",
        "#Next find the roots of the word\n",
        "for w in nltk_tokens:\n",
        "       print (\"Actual: %s  Stem: %s\"  % (w,porter_stemmer.stem(w)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual: It  Stem: It\n",
            "Actual: originated  Stem: origin\n",
            "Actual: from  Stem: from\n",
            "Actual: the  Stem: the\n",
            "Actual: idea  Stem: idea\n",
            "Actual: that  Stem: that\n",
            "Actual: there  Stem: there\n",
            "Actual: are  Stem: are\n",
            "Actual: readers  Stem: reader\n",
            "Actual: who  Stem: who\n",
            "Actual: prefer  Stem: prefer\n",
            "Actual: learning  Stem: learn\n",
            "Actual: new  Stem: new\n",
            "Actual: skills  Stem: skill\n",
            "Actual: from  Stem: from\n",
            "Actual: the  Stem: the\n",
            "Actual: comforts  Stem: comfort\n",
            "Actual: of  Stem: of\n",
            "Actual: their  Stem: their\n",
            "Actual: drawing  Stem: draw\n",
            "Actual: rooms  Stem: room\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z0q_O7DUwhy-",
        "colab_type": "code",
        "outputId": "7068642b-fc97-4e79-a2af-6bdf2a559ecb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Lemmatization \n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "nltk_tokens = nltk.word_tokenize(data)\n",
        "for w in nltk_tokens:\n",
        "       print (\"Actual: %s  Lemma: %s\"  % (w,wordnet_lemmatizer.lemmatize(w)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual: It  Lemma: It\n",
            "Actual: originated  Lemma: originated\n",
            "Actual: from  Lemma: from\n",
            "Actual: the  Lemma: the\n",
            "Actual: idea  Lemma: idea\n",
            "Actual: that  Lemma: that\n",
            "Actual: there  Lemma: there\n",
            "Actual: are  Lemma: are\n",
            "Actual: readers  Lemma: reader\n",
            "Actual: who  Lemma: who\n",
            "Actual: prefer  Lemma: prefer\n",
            "Actual: learning  Lemma: learning\n",
            "Actual: new  Lemma: new\n",
            "Actual: skills  Lemma: skill\n",
            "Actual: from  Lemma: from\n",
            "Actual: the  Lemma: the\n",
            "Actual: comforts  Lemma: comfort\n",
            "Actual: of  Lemma: of\n",
            "Actual: their  Lemma: their\n",
            "Actual: drawing  Lemma: drawing\n",
            "Actual: rooms  Lemma: room\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KP76XUoP1hMq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Stop Words"
      ]
    },
    {
      "metadata": {
        "id": "dT6IYVzoxaqi",
        "colab_type": "code",
        "outputId": "9d848aa7-d58e-4beb-aa56-1f2fd1718be5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Removing stopwords\n",
        "sentences = nltk.sent_tokenize(data)\n",
        "for i in range(len(sentences)):\n",
        "    words = nltk.word_tokenize(sentences[i])\n",
        "    words = [word for word in words if word not in stopwords.words('english')]\n",
        "    sentences[i] = ' '.join(words)    \n",
        "sentences"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['It originated idea readers prefer learning new skills comforts drawing rooms']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "5WMwARg41kxV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Part-Of-Speech Tagging"
      ]
    },
    {
      "metadata": {
        "id": "HzNEbBnh02ys",
        "colab_type": "code",
        "outputId": "803e11d8-197e-4961-b631-4bc44740a61f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "#@title POS Tagging\n",
        "words = nltk.word_tokenize(data)\n",
        "tagged_words = nltk.pos_tag(words)\n",
        "# Tagged word paragraph\n",
        "word_tags = []\n",
        "for tw in tagged_words:\n",
        "    word_tags.append(tw[0]+\"_\"+tw[1])\n",
        "\n",
        "tagged_paragraph = ' '.join(word_tags)\n",
        "tagged_paragraph"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'It_PRP originated_VBD from_IN the_DT idea_NN that_IN there_EX are_VBP readers_NNS who_WP prefer_VBP learning_VBG new_JJ skills_NNS from_IN the_DT comforts_NNS of_IN their_PRP$ drawing_NN rooms_NNS'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "CdlrOvlE4K1R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Word Count"
      ]
    },
    {
      "metadata": {
        "id": "FbIrhtQp2YJs",
        "colab_type": "code",
        "outputId": "5e3535db-52d0-4f96-fb95-aa3bb5155d05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Creating word histogram (Word Count or Map Reduce)\n",
        "dataset = nltk.sent_tokenize(data)\n",
        "for i in range(len(dataset)):\n",
        "    dataset[i] = dataset[i].lower()\n",
        "    dataset[i] = re.sub(r'\\W',' ',dataset[i])\n",
        "    dataset[i] = re.sub(r'\\s+',' ',dataset[i])\n",
        "word2count = {}\n",
        "for d in dataset:\n",
        "    words = nltk.word_tokenize(d)\n",
        "    for word in words:\n",
        "        if word not in word2count.keys():\n",
        "            word2count[word] = 1\n",
        "        else:\n",
        "            word2count[word] += 1\n",
        "word2count"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'are': 1,\n",
              " 'comforts': 1,\n",
              " 'drawing': 1,\n",
              " 'from': 2,\n",
              " 'idea': 1,\n",
              " 'it': 1,\n",
              " 'learning': 1,\n",
              " 'new': 1,\n",
              " 'of': 1,\n",
              " 'originated': 1,\n",
              " 'prefer': 1,\n",
              " 'readers': 1,\n",
              " 'rooms': 1,\n",
              " 'skills': 1,\n",
              " 'that': 1,\n",
              " 'the': 2,\n",
              " 'their': 1,\n",
              " 'there': 1,\n",
              " 'who': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "7a5PcgRg29rX",
        "colab_type": "code",
        "outputId": "978d5b64-18a7-40ac-f945-4507be7edfaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Selecting best features\n",
        "# Tokenize sentences\n",
        "dataset = nltk.sent_tokenize(data)\n",
        "for i in range(len(dataset)):\n",
        "    dataset[i] = dataset[i].lower()\n",
        "    dataset[i] = re.sub(r'\\W',' ',dataset[i])\n",
        "    dataset[i] = re.sub(r'\\s+',' ',dataset[i])\n",
        "\n",
        "\n",
        "# Creating word histogram\n",
        "word2count = {}\n",
        "for d1 in dataset:\n",
        "    words = nltk.word_tokenize(d1)\n",
        "    for word in words:\n",
        "        if word not in word2count.keys():\n",
        "            word2count[word] = 1\n",
        "        else:\n",
        "            word2count[word] += 1\n",
        "freq_words = heapq.nlargest(3,word2count,key=word2count.get)\n",
        "freq_words"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['from', 'the', 'it']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "6sBdY3Ec6cCr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Synonyms and Antonyms"
      ]
    },
    {
      "metadata": {
        "id": "d4SZ93q_4coX",
        "colab_type": "code",
        "outputId": "cdd70439-b399-4479-b468-6a10876ba26e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "#@title synonyms and antonyms\n",
        "synonyms = []\n",
        "antonyms = []\n",
        "\n",
        "for syn in wordnet.synsets(\"good\"):\n",
        "    for s in syn.lemmas():\n",
        "        synonyms.append(s.name())\n",
        "        for a in s.antonyms():\n",
        "            antonyms.append(a.name())\n",
        "            \n",
        "print(set(synonyms))\n",
        "print(set(antonyms))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'well', 'honest', 'safe', 'unspoiled', 'estimable', 'practiced', 'goodness', 'just', 'good', 'near', 'secure', 'beneficial', 'proficient', 'adept', 'dear', 'full', 'undecomposed', 'ripe', 'honorable', 'unspoilt', 'sound', 'dependable', 'right', 'trade_good', 'commodity', 'serious', 'thoroughly', 'effective', 'expert', 'skilful', 'in_force', 'skillful', 'respectable', 'soundly', 'upright', 'in_effect', 'salutary'}\n",
            "{'bad', 'ill', 'evilness', 'badness', 'evil'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NWLIGXxT7jIT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Exercises\n",
        "**1. Scrap NITT Wikipedia Page (https://en.wikipedia.org/wiki/National_Institute_of_Technology,_Tiruchirappalli) and apply above concepts**\n",
        "\n",
        "**2. Scrap Palindrome words from (http://www.word-buff.com/single-word-palindromes.html) and find it's synonyms and antonyms in both CPU and GPU and Calculte it's processing time**"
      ]
    },
    {
      "metadata": {
        "id": "qUajhX1H51ja",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}